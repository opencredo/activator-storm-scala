<!DOCTYPE html>
<html>
<head>
    <title>Apache Storm, Hazelcast and Scala</title>
</head>
<body>
    <div>
        <h2>Overview</h2>
        <p>This template is a Scala-based, real-time word count example, using Apache Storm.
            We demonstrate how Scala can be used with ease to implement Storm components,
            thanks to its convenience of interoperation with Java.</p>
        <p>This template contains two Storm topologies: one that uses in-memory maps and stateful dispatching to process and store
            word counts, and one that uses Hazelcast as an in-memory data grid.</p>
    </div>
    <div>
        <h2>Apache Storm</h2>
        <p><a href="https://storm.apache.org/">Apache Storm</a> is distributed, scalable and fault-tolerant open source real-time computation system. Storm has a simple API to create
            graphs of distributed components, called topologies.</p>
        <p><img src="https://storm.apache.org/images/topology.png"></p>
        <p>To do real-time computation on Storm, you create what are called "topologies". A topology is a graph of computation.
            Each node in a topology contains processing logic, and links between nodes indicate how data should be passed around between nodes.</p>
        <p>One of the core abstractions in Storm is the concept of a stream, which is an unbounded sequence of tuples.
            Each stream starts with a component called a spout that is responsible of emitting data tuples into the stream.
            The spout is typically combined with any number of bolts to process and transform the data.</p>
        <p>Each node in a Storm topology executes in parallel. In your topology, you can specify how much parallelism you want for each node,
            and then Storm will spawn that number of threads across the cluster to do the execution.</p>
        <p>A topology runs forever, or until you kill it. Storm will automatically reassign any failed tasks.
            Additionally, Storm guarantees that there will be no data loss, even if machines go down and messages are dropped.</p>
    </div>
    <div>
        <h2>Hazelcast</h2>
        <p><a href="http://hazelcast.com/">Hazelcast</a> is a scalable Java-based open source in-memory data grid.
            In-memory data grids are often used with databases in order to improve performance of applications,
            to distribute data and computation across servers, clusters and geographies, and to manage very large data sets
            or high data ingest rates.</p>
        <p>Hazelcast can be used for the following use cases:</p>
        <ul>
            <li>Caching - Hazelcast can be used as distributed cache, reliably storing considerable amount of data</li>
            <li>NoSQL - Hazelcast can be used as a high-performance in-memory key-value data store</li>
            <li>In-Memory Data Grid - Hazelcast can be used as a messaging platform or a compute grid</li>
            <li>Web Session Clustering - Hazelcast can be using as a distributed store for web sessions, enabling scaling out web applications</li>
        </ul>
    </div>
    <div>
        <h2>The anatomy of Storm topology</h2>
        <h3>Data model</h3>
        <p>Storm uses tuples as its data model. A tuple is a named list of values, and a field in a tuple can be an object of any type.
            Out of the box, Storm supports all the primitive types, strings, and byte arrays as tuple field values.
            To use an object of another type, you just need to implement a serializer for the type.</p>
        <p>Every node in a topology must declare the output fields for the tuples it emits. Here is an example:</p>
        <pre><code>override def declareOutputFields(declarer: OutputFieldsDeclarer) {
    declarer.declare(new Fields("word", "count"))
}</code></pre>
        <h3>Spout</h3>
        <p>Spout nodes in Storm topologies are responsible for emiting tuples into the topology.
            Spouts typically integrate with external data sources, like persistence data stores, messaging systems or web services.
            In this template we implemented a simple spout that sources data from a internal collection.</p>
        <pre><code>override def nextTuple(): Unit = {
    collector.emit(List[AnyRef](nextSentence).asJava)
}</code></pre>
        <h3>Bolt</h3>
        <p>Bolt nodes in Storm topologies are responsible for processing the data received in tuples and either emitting tuples back into the topology
            or outside of the topology, into persistent data store, messaging system, web service, etc. We use Hazelcast as an external data store in
            <a href="#code/src/main/scala/com/opencredo/storm/HazelcastWordCounterBolt.scala">HazelcastWordCounterBolt</a>.</p>
        <pre><code>override def execute(input: Tuple) = {
    val word = input.getStringByField("word")
    val count = input.getIntegerByField("count")

    wordCount.lock(word)
    try {
        val total = Option(wordCount.get(word))
        wordCount.put(word, total.getOrElse(0) + count)
    } finally {
        wordCount.unlock(word)
    }

    collector.ack(input)
}</code></pre>
        <h3>Topology</h3>
        <p>Topologies are graphs of stream transformations that can be submitted for the execution to Storm clusters.</p>
        <p><code>TopologyBuilder</code> can be used to compose a topology by adding spouts and bolts accompanied by the number of desired instances of these nodes
        across the Storm cluster and the type of grouping to be used for distributing data tuples along topology graph edges.</p>
        <pre><code>val builder = new TopologyBuilder
            builder.setSpout("generator", new RandomSentenceGeneratorSpout, 1)
            builder.setBolt("splitter", new SentenceSplitterBolt, 3).shuffleGrouping("generator")
            builder.setBolt("counter", new InMemoryWordCounterBolt, 3).fieldsGrouping("split", new Fields("word"))

            val topology: StormTopology = builder.createTopology</code></pre>
    </div>
    <div>
        <h2>Word count topology</h2>
        <p>In this template, we demonstrate how to implement a <a href="https://en.wikipedia.org/wiki/Word_count">word count</a>
            functionality using Storm's distributed computation capabilities.</p>
        <p>Counting words requires a source of text. <a href="#code/src/main/scala/com/opencredo/storm/RandomSentenceGeneratorSpout.scala">RandomSentenceGeneratorSpout</a>
            is a spout that emits a continuous stream of sentences being randomly picked from the predefined list.</p>
        <p>The next stage in the processing flow is splitting sentences into words. This is accomplished by <a href="#code/src/main/scala/com/opencredo/storm/SentenceSplitterBolt.scala">SentenceSplitterBolt</a>
            that splits sentences into words and emits tuples consisting of the word and the count of one (used for further aggregation).
            Tasks in Storm are executed in parallel, so we need to tell storm how tuples should be routed between multiple nodes.
            In case of <code>SentenceSplitterBolt</code> we can use the shuffle grouping that will distribute sentence tuples evenly between all splitter tasks.</p>
        <p>The last step of the topology involves counting all the word tuples.
            <a href="#code/src/main/scala/com/opencredo/storm/InMemoryWordCounterBolt.scala">InMemoryWordCounterBolt</a> uses a <code>mutable.Map</code> to count words.
            We need to use field grouping on the word field to make sure word tuples are directed by Storm to the right bolt for counting.
            If we opted for shuffle grouping each of the multiple <code>InMemoryWordCounterBolt</code>s would be storing partial counts
            and we would need to aggregate all the counts somehow (this is what the topology using Hazelcast addresses).</p>
        <p>To see the basic word count topology in action <a href="#run">run</a> the application using
            <a href="#code/src/main/scala/com/opencredo/storm/InMemoryWordCountTopology.scala">InMemoryWordCountTopology</a> main class.</p>

    </div>
    <div>
        <h2>Word count topology with Hazelcast</h2>
        <p>In the basic implementation of the word-counting topology we use a <code>mutable.Map</code> to store word counts in
            <a href="#code/src/main/scala/com/opencredo/storm/InMemoryWordCounterBolt.scala">InMemoryWordCounterBolt</a>,
            which combined with field grouping allows to effectively count words across a number of bolt instances.
            The downside of this approach is that word counts are stored in memory across multiple <code>mutable.Map</code>s
            and there is no easy way to collate them as the topology processes the stream of sentences.</p>
        <p>Apache Storm usually utilises external persistent stores or messaging solutions to push the outcome of stream processing to.
            In this template we use Hazelcast as a distributed in-memory cache to keep word counts outside of the Storm topology.
            <a href="#code/src/main/scala/com/opencredo/storm/HazelcastWordCounterBolt.scala">HazelcastWordCounterBolt</a>
            connects to the Hazelcast cluster and uses a distributed map to store word counts, which also means that we can use shuffle grouping.
            This map can be interrogated after the topology has been stopped to retrieve the final counts for all the words.</p>
        <p>This is exactly what <a href="#code/src/main/scala/com/opencredo/storm/HazelcastWordCountTopology.scala">HazelcastWordCountTopology</a>
            does, so if you <a href="#run">run</a> the application using this main class you will get the total word counts in the console output,
            even after the Storm cluster has been terminated.</p>
    </div>
    <div>
        <h2>Testing Storm topologies</h2>
        <p>Testing distributed computation systems is not an easy task, given the complexity such systems usually involve.
            Storm is not an exception in that regard, but luckily provides some facilities that help testing topologies in a controlled environment.</p>
        <p>Before we discuss testing topologies, it definitely helps to verify the behaviour of their building blocks, spouts and bolts.
            This template includes a <a href="#code/src/test/scala/com/opencredo/storm/RandomSentenceGeneratorSpoutSpec.scala">RandomSentenceGeneratorSpoutSpec</a>
            that exercises the spout generating random sentences, as well as <a href="#code/src/test/scala/com/opencredo/storm/SentenceSplitterBoltSpec.scala">SentenceSplitterBoltSpec</a>
            that tests the bolt responsible for splitting sentences into words. We are using <a href="http://www.scalatest.org/">ScalaTest's</a> <code>WordSpec</code> to make sure test cases
            are sufficiently descriptive and well structured. <a href="https://code.google.com/p/mockito/">Mockito</a> is used for mocking dependencies in unit tests.</p>
        <p>When it come to testing word-counting bolts, we have to consider two variants and apply appropriate testing approach to both of them.
            <a href="#code/src/test/scala/com/opencredo/storm/InMemoryWordCounterBoltSpec.scala">InMemoryWordCounterBoltSpec</a>
            tests the in-memory version of the bolt, and asserts that word counts are stored in <code>mutable.Map</code> internal to the bolt class.
            In <a href="#code/src/test/scala/com/opencredo/storm/HazelcastWordCounterBoltSpec.scala">HazelcastWordCounterBoltSpec</a>
            we need to take a different approach as the bolt communicates to the Hazelcast cluster over TCP and mocking out
            any dependencies outside of the Storm API is not possible due to the distributed nature of Storm (only serializable
            config properties can be used). The test creates a Hazelcast cluster and passes connection details to the bolt using the Storm
            configuration mechanism. Hazelcast is then used to assert that the word counts that the bolt stores in the distributed map are correct.</p>
        <p>With unit tests we can exercise spouts and bolts in isolation (or with minimal dependencies) but this alone won't give
            us full confidence that when all nodes are put together and working in parallel (as they do in Storm) the entire topology will behave
            as expected. <a href="#code/src/test/scala/com/opencredo/storm/HazelcastWordCountTopologyIntegrationSpec.scala">HazelcastWordCountTopologyIntegrationSpec</a>
            uses Storm's testing framework to run topology in a controlled environment and with the ability to inject test data as opposed to using
            our sentence generating spout. In this test we start a Hazelcast cluster again and validate the word counts after the topology has
            completed processing all the tuples injected by the framework.</p>
    </div>

</body>
</html>
